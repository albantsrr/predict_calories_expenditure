{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Hill Climbing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCE\n",
    "https://www.kaggle.com/code/cdeotte/gpu-hill-climbing-cv-0-05930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../dataset/train.csv')\n",
    "test_df = pd.read_csv('../../dataset/test.csv')\n",
    "true = np.log1p( train_df.Calories.values )\n",
    "\n",
    "VER = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OOF and Test PREDS\n",
    "\n",
    "We load all our OOF and Test PREDs. The code below attempts to detect if your OOF have log1p applied or not. It will then apply log1p if it is not already applied. The code below assumes that submission.csv files do not have log1p applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "=> xgb \n",
      "=> cat \n",
      "=> nn \n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "X_train = []\n",
    "X_test = []\n",
    "PATH = \"../predictions\"\n",
    "nb_iterations = 1\n",
    "\n",
    "\n",
    "print(\"Loading files...\")\n",
    "for c in ['xgb','cat', 'nn']:\n",
    "    for i in range(1, nb_iterations + 1):\n",
    "        print(f\"=> {c} \",end=\"\")\n",
    "        oof = np.load(f\"{PATH}/oof/{c}_oof_predictions_{i}.npy\")\n",
    "        # IF NOT LOG1P THEN APPLY LOG1P\n",
    "        if oof.mean()>10: oof = np.log1p(oof)\n",
    "        X_train.append(oof)\n",
    "        files.append(f\"oof_{c}\")\n",
    "        df = pd.read_csv(f\"{PATH}/submissions/{c}_submission_{i}.csv\")\n",
    "        pred = np.log1p( df.Calories.values )\n",
    "        X_test.append(pred)\n",
    "        print()\n",
    "\n",
    "\n",
    "# print(\"Loading files...\")\n",
    "# for c in ['xgb','cat']:\n",
    "#     for i in range(1, nb_iterations + 1):\n",
    "#         print(f\"=> {c} \",end=\"\")\n",
    "#         oof = np.load(f\"{PATH}/oof/{c}_oof_predictions_{i}.npy\")\n",
    "#         # IF NOT LOG1P THEN APPLY LOG1P\n",
    "#         if oof.mean()>10: oof = np.log1p(oof)\n",
    "#         X_train.append(oof)\n",
    "#         files.append(f\"oof_{c}\")\n",
    "#         df = pd.read_csv(f\"{PATH}/submissions/{c}_submission_{i}.csv\")\n",
    "#         pred = np.log1p( df.Calories.values )\n",
    "#         print(pred)\n",
    "#         X_test.append(pred)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our combined OOF have shape: (750000, 3)\n",
      "Our combined PRED have shape: (250000, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.stack(X_train).T\n",
    "print(\"Our combined OOF have shape:\",x_train.shape)\n",
    "\n",
    "x_test = np.stack(X_test).T\n",
    "print(\"Our combined PRED have shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Single Model\n",
    "\n",
    "Hill climbing begins with our strongest model. So first we will find the strongest model by computing the CV score for each model. The competition metric is RMSLE. We have converted the ground truth with log1p and converted all OOF with log1p. Therefore below we will just compute the metric RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oof_xgb', 'oof_cat', 'oof_nn']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.05992 oof_xgb\n",
      "RMSE 0.05968 oof_cat\n",
      "RMSE 0.06245 oof_nn\n",
      "\n",
      "Best single model is oof_cat with RMSE = 0.05968\n"
     ]
    }
   ],
   "source": [
    "def compute_metric_rmse(p):\n",
    "    m = np.sqrt(np.mean( (p-true)**2.0 ) )\n",
    "    return m\n",
    "\n",
    "# COMPUTE METRIC FOR EACH OOF\n",
    "best_score = 40\n",
    "best_index = -1\n",
    "\n",
    "for k,name in enumerate( files ):\n",
    "    s = compute_metric_rmse(x_train[:,k])\n",
    "    if s < best_score:\n",
    "        best_score = s\n",
    "        best_index = k\n",
    "    print(f'RMSE {s:0.5f} {name}') \n",
    "print()\n",
    "print(f'Best single model is {files[best_index]} with RMSE = {best_score:0.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU METRIC Computation \n",
    "\n",
    "To perform hill climbing quickly, we will compute RMSE metric in batch form on GPU. This makes a big difference when we begin to have 100s or 1000s of models in our hill climbing search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp, gc\n",
    "\n",
    "def multiple_rmse_scores(actual, predicted):\n",
    "    \"\"\"\n",
    "    Computes multiple approximate AUC scores using GPU.\n",
    "    \n",
    "    This function calculates K approximate AUC scores simultaneously for a binary classification \n",
    "    problem. The implementation does not handle ties in predictions correctly, making it an \n",
    "    approximate AUC computation. The function is based on the algorithm outlined in:\n",
    "    https://github.com/benhamner/Metrics/blob/master/R/R/metrics.r\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    actual : cupy.ndarray\n",
    "        A 1D GPU array of shape (N,), where N is the number of samples. \n",
    "        Contains binary values (0 or 1) indicating the true labels.\n",
    "    \n",
    "    predicted : cupy.ndarray\n",
    "        A 2D GPU array of shape (N, K), where K is the number of classifiers.\n",
    "        Each column contains predicted scores for the corresponding classifier.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    cupy.ndarray\n",
    "        A 1D GPU array of shape (K,) containing the AUC scores for each classifier.\n",
    "\n",
    "    \"\"\"\n",
    "    if len(actual.shape)==1: \n",
    "        actual = actual[:,cp.newaxis]\n",
    "    m = cp.sqrt(cp.mean(  (actual-predicted)**2.0,axis=0 ))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climb\n",
    "\n",
    "We will now try adding more models one by one. When a new model improves our ensemble CV score, we keep it. Otherwise, we do not add it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 We begin with best single model RMSE 0.05968 from \"oof_cat\"\n",
      "1 New best RMSE 0.05938639408128328 adding \"oof_xgb\" with weight 0.420\n",
      "2 New best RMSE 0.05936387826195298 adding \"oof_nn\" with weight 0.080\n",
      "=> We reached tolerance 1e-05\n"
     ]
    }
   ],
   "source": [
    "USE_NEGATIVE_WGT = True\n",
    "MAX_MODELS = 1000\n",
    "TOL = 1e-5\n",
    "\n",
    "indices = [best_index]\n",
    "old_best_score = best_score\n",
    "print(f'0 We begin with best single model RMSE {best_score:0.5f} from \"{files[best_index]}\"')\n",
    "\n",
    "# PREPARE/MOVE VARIABLES TO GPU FOR SPEED UP\n",
    "x_train2 = cp.array( x_train ) #GPU\n",
    "best_ensemble = x_train2[:,best_index] # GPU\n",
    "truth = cp.array( true ) # GPU\n",
    "start = -0.50\n",
    "if not USE_NEGATIVE_WGT: start = 0.01\n",
    "ww = cp.arange(start,0.51,0.01) # GPU\n",
    "nn = len(ww)\n",
    "\n",
    "# BEGIN HILL CLIMBING\n",
    "models = [best_index]\n",
    "weights = []\n",
    "metrics = [best_score]\n",
    "\n",
    "for kk in range(1_000_000):\n",
    "\n",
    "    best_score = 40\n",
    "    best_index = -1\n",
    "    best_weight = 0\n",
    "\n",
    "    # TRY ADDING ONE MORE MODEL\n",
    "    for k,ff in enumerate(files):\n",
    "        new_model = x_train2[:,k] # GPU\n",
    "        m1 = cp.repeat(best_ensemble[:, cp.newaxis], nn, axis=1) * (1-ww) # GPU\n",
    "        m2 = cp.repeat(new_model[:, cp.newaxis], nn, axis=1) * ww # GPU\n",
    "        mm = m1+m2 # GPU\n",
    "        new_aucs = multiple_rmse_scores(truth, mm)\n",
    "        new_score = cp.min(new_aucs).item() # GPU -> CPU\n",
    "        if new_score < best_score:\n",
    "            best_score = new_score # CPU\n",
    "            best_index = k # CPU\n",
    "            ii = np.argmin(new_aucs).item() # GPU -> CPU\n",
    "            best_weight = ww[ii].item() # GPU -> CPU\n",
    "            potential_ensemble = mm[:,ii] # GPU\n",
    "    del new_model, m1, m2, mm, new_aucs, new_score\n",
    "    gc.collect()\n",
    "\n",
    "    # STOPPING CRITERIA\n",
    "    indices.append(best_index)\n",
    "    indices = list(np.unique(indices))\n",
    "    if len(indices)>MAX_MODELS:\n",
    "        print(f'=> We reached {MAX_MODELS} models')\n",
    "        indices = indices[:-1]\n",
    "        break\n",
    "    if -1*(best_score - old_best_score) < TOL: \n",
    "        print(f'=> We reached tolerance {TOL}')\n",
    "        break\n",
    "\n",
    "    # RECORD NEW RESULT\n",
    "    print(kk+1,'New best RMSE',best_score,f'adding \"{files[best_index]}\"','with weight',f'{best_weight:0.3f}')\n",
    "    models.append(best_index)\n",
    "    weights.append(best_weight)\n",
    "    metrics.append(best_score)\n",
    "    best_ensemble = potential_ensemble\n",
    "    old_best_score = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Weights\n",
    "The dataframe below shows us what models were selected and what weights are assigned to each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weight",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "36a6ef8d-39e3-4713-9920-3f07a759230e",
       "rows": [
        [
         "0",
         "oof_cat",
         "0.5336"
        ],
        [
         "1",
         "oof_xgb",
         "0.3864"
        ],
        [
         "2",
         "oof_nn",
         "0.08000000000000002"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oof_cat</td>\n",
       "      <td>0.5336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oof_xgb</td>\n",
       "      <td>0.3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oof_nn</td>\n",
       "      <td>0.0800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  weight\n",
       "0  oof_cat  0.5336\n",
       "1  oof_xgb  0.3864\n",
       "2   oof_nn  0.0800"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt = np.array([1])\n",
    "for w in weights:\n",
    "    wgt = wgt*(1-w)\n",
    "    wgt = np.concatenate([wgt,np.array([w])])\n",
    "    \n",
    "rows = []\n",
    "t = 0\n",
    "for m,w,s in zip(models,wgt,metrics):\n",
    "    name = files[m]\n",
    "    dd = {}\n",
    "    dd['weight'] = w\n",
    "    dd['model'] = name\n",
    "    rows.append(dd)\n",
    "    t += float( f'{w:.3f}' )\n",
    "\n",
    "# DISPLAY WEIGHT PER MODEL\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.groupby('model').agg('sum').reset_index().sort_values('weight',ascending=False)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble weights sum to 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Ensemble weights sum to',df.weight.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Overall CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Hill climbing RMSE = 0.059364\n"
     ]
    }
   ],
   "source": [
    "# COMBINE OOF PREDITIONS (using weights from hill climbing)\n",
    "x_map = {x:y for x,y in zip(files,np.arange(len(files)))}\n",
    "x_train3 = x_train2.get()\n",
    "ensemble = x_train3[:, x_map[df.model.iloc[0]] ] * df.weight.iloc[0]\n",
    "for k in range(1,len(df)):\n",
    "    ensemble += x_train3[:, x_map[df.model.iloc[k]] ] * df.weight.iloc[k]\n",
    "m = compute_metric_rmse(ensemble)\n",
    "print(f'Overall Hill climbing RMSE = {m:0.6f}')\n",
    "\n",
    "np.save(f'../predictions/oof/oof_hill_climb_v{VER}',ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE TEST PREDITIONS (using weights from hill climbing)\n",
    "x_map = {x:y for x,y in zip(files,np.arange(len(files)))}\n",
    "pred = x_test[:, x_map[df.model.iloc[0]] ] * df.weight.iloc[0]\n",
    "for k in range(1,len(df)):\n",
    "    pred += x_test[:, x_map[df.model.iloc[k]] ] * df.weight.iloc[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (250000, 2)\n",
      "Test target mean is 88.16914323279593\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Calories",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a773d13f-d839-42c4-9771-a578332b9151",
       "rows": [
        [
         "0",
         "750000",
         "27.447716192949905"
        ],
        [
         "1",
         "750001",
         "107.83853222842403"
        ],
        [
         "2",
         "750002",
         "87.35129215875573"
        ],
        [
         "3",
         "750003",
         "125.98714626840815"
        ],
        [
         "4",
         "750004",
         "75.92180272190096"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000</td>\n",
       "      <td>27.447716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750001</td>\n",
       "      <td>107.838532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750002</td>\n",
       "      <td>87.351292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750003</td>\n",
       "      <td>125.987146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750004</td>\n",
       "      <td>75.921803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    Calories\n",
       "0  750000   27.447716\n",
       "1  750001  107.838532\n",
       "2  750002   87.351292\n",
       "3  750003  125.987146\n",
       "4  750004   75.921803"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WRITE SUB TO CSV\n",
    "sub = pd.read_csv(\"../../dataset/sample_submission.csv\")\n",
    "\n",
    "# CLIP TO TRAIN MIN AND MAX\n",
    "mn = train_df.Calories.min(); mx = train_df.Calories.max()\n",
    "sub.Calories = np.clip( np.expm1( pred ),mn,mx )\n",
    "\n",
    "print(\"Test shape\", sub.shape )\n",
    "print(\"Test target mean is\", sub.Calories.mean())\n",
    "sub.to_csv(f\"../predictions/submissions/hill_climb_submission_v{VER}.csv\",index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
